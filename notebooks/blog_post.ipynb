{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from typing import TypedDict, List, Dict\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ['OPENAI_API_KEY'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Section(TypedDict):\n",
    "    heading: str\n",
    "    content: str\n",
    "\n",
    "class BlogPost(TypedDict):\n",
    "    topic: str\n",
    "    headline: str\n",
    "    introduction: str\n",
    "    sections: List[Section]\n",
    "    conclusion: str\n",
    "    call_to_action: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_blog_post(topic: str, context: str, style: str = \"informative\", word_count: int = 600, audience: str = \"general public\", tone: str = \"neutral\") -> BlogPost:\n",
    "    # Craft a detailed prompt based on the parameters\n",
    "    prompt = (\n",
    "        f\"Topic: {topic}\\n\"\n",
    "        f\"Context: {context}\\n\"\n",
    "        f\"Audience: {audience}\\n\"\n",
    "        f\"Tone: {tone}\\n\"\n",
    "        f\"Style: {style}\\n\"\n",
    "\n",
    "        \"Based on the information above, generate a title and a {style} blog post that is approximately {word_count} words long. Ensure the content is tailored for the {audience} audience, maintains a {tone} tone, and covers the topic and context provided. There should be an intro, no more than 3 sections, a conclusion, and a call to action to visit lawassistant.ai. Do not plagiarize the context. Provide me the output in JSON format with the following structure: \"\n",
    "        \n",
    "        \"{\\\"topic\\\": \\\"<Your Topic Here>\\\", \\\"headline\\\": \\\"<Your Headline Here>\\\", \\\"introduction\\\": \\\"<Your Introduction Here>\\\", \\\"sections\\\": [{\\\"heading\\\": \\\"Start With the Right Blog Post Topic\\\", \\\"content\\\": \\\"<Content Here>\\\"}, {\\\"heading\\\": \\\"Create a Descriptive and Compelling Headline\\\", \\\"content\\\": \\\"<Content Here>\\\"}, {\\\"heading\\\": \\\"Write a Clear and Concise Introduction\\\", \\\"content\\\": \\\"<Content Here>\\\"}, {\\\"heading\\\": \\\"Break Up Content with Headings\\\", \\\"content\\\": \\\"<Content Here>\\\"}, {\\\"heading\\\": \\\"Keep Paragraphs and Sentences Short\\\", \\\"content\\\": \\\"<Content Here>\\\"}, {\\\"heading\\\": \\\"Add Images, Video, and Other Media\\\", \\\"content\\\": \\\"<Content Here>\\\"}, {\\\"heading\\\": \\\"Wrap Up Blog Posts With a Conclusion\\\", \\\"content\\\": \\\"<Content Here>\\\"}, {\\\"heading\\\": \\\"End With a Compelling Call To Action (CTA)\\\", \\\"content\\\": \\\"<Content Here>\\\"}], \\\"conclusion\\\": \\\"<Your Conclusion Here>\\\", \\\"call_to_action\\\": \\\"<Your Call to Action Here>\\\"}. All text within the title and content should have proper markdown formatting. \"\n",
    "    )\n",
    "\n",
    "    # Calculate the number of tokens approximately needed (assuming 4 tokens per word for the content plus additional tokens for the prompt)\n",
    "    max_tokens = int(word_count * 4) + len(prompt.split())\n",
    "\n",
    "    # Generate the blog post content using OpenAI's GPT-4\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-4-0125-preview\",\n",
    "        max_tokens=max_tokens, \n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    # Assuming the model generates the title and content separated by a newline, split them accordingly\n",
    "    generated_output: str = chat_completion.choices[0].message.content # type: ignore\n",
    "    json_output = json.loads(generated_output)\n",
    "\n",
    "    blog_object: BlogPost = {\n",
    "    \"topic\": json_output[\"topic\"],\n",
    "    \"headline\": json_output[\"headline\"],\n",
    "    \"introduction\": json_output[\"introduction\"],\n",
    "    \"sections\": json_output[\"sections\"],\n",
    "    \"conclusion\": json_output[\"conclusion\"],\n",
    "    \"call_to_action\": json_output[\"call_to_action\"]\n",
    "}\n",
    "\n",
    "\n",
    "    return blog_object\n",
    "\n",
    "def generate_blog_as_text(topic: str, context: str, style: str = \"informative\", word_count: int = 600, audience: str = \"general public\", tone: str = \"neutral\") -> str:\n",
    "    # should be same logic as in the generate_blog_post, but this time just return a string with markdown\n",
    "    prompt = (\n",
    "        f\"Topic: {topic}\\n\"\n",
    "        f\"Context: {context}\\n\"\n",
    "        f\"Audience: {audience}\\n\"\n",
    "        f\"Tone: {tone}\\n\"\n",
    "        f\"Style: {style}\\n\"\n",
    "        \n",
    "\n",
    "        \"Based on the information above, generate a title and a {style} blog post that is approximately {word_count} words long. Ensure the content is tailored for the {audience} audience, maintains a {tone} tone, and covers the topic and context provided. There should be an intro, no more than 2 interesting sections, a conclusion, and a call to action to visit lawassistant.ai. Do not plagiarize the context. You should not mentino any other company than Law Assistant AI. \"\n",
    "        \n",
    "    )\n",
    "     # Calculate the number of tokens approximately needed (assuming 4 tokens per word for the content plus additional tokens for the prompt)\n",
    "    max_tokens = int(word_count * 4) + len(prompt.split())\n",
    "\n",
    "    # Generate the blog post content using OpenAI's GPT-4\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        max_tokens=max_tokens, \n",
    "        temperature=0,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    generated_output: str = chat_completion.choices[0].message.content\n",
    "    return generated_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Future of Compliance: How AI is Revolutionizing the Industry\n",
      "\n",
      "Introduction:\n",
      "In today's fast-paced business world, compliance with regulations and laws is more critical than ever. With the help of artificial intelligence (AI), compliance automation is transforming the way organizations manage their compliance processes. This blog post will explore the benefits of compliance automation using AI, how it works, and some interesting use cases that demonstrate its effectiveness.\n",
      "\n",
      "Section 1: How Compliance Automation Works\n",
      "Compliance automation tools leverage AI technology to streamline, optimize, and enhance compliance processes. These tools can analyze data, provide real-time alerts on new regulations, and automate policy management. By using generative AI, compliance professionals can save time, monitor compliance gaps, and ensure that their processes are effective. AI-powered chatbots can provide instant answers to compliance questions, making it easier for employees to stay compliant.\n",
      "\n",
      "Section 2: Use Cases for Compliance Automation\n",
      "Compliance automation is essential for demystifying regulations, streamlining questionnaires, auditing with precision, automating email responses, and nurturing conversational compliance. AI acts as a modern Rosetta Stone for regulations, translating complex legal text into understandable answers. By automating tasks like filling out forms and drafting correspondences, compliance professionals can focus on strategic initiatives and mitigate risks more effectively.\n",
      "\n",
      "Section 3: Benefits of Compliance Automation\n",
      "The benefits of compliance automation using AI include enhanced productivity, mitigated risk, and greater employee compliance. By automating repetitive tasks, compliance professionals can focus on higher-level strategic initiatives. Automated compliance chatbots can test policies against regulations, fine-tune processes, and make it easier for employees to find answers to their compliance questions. This results in a more efficient and effective compliance program overall.\n",
      "\n",
      "Conclusion:\n",
      "In an ever-evolving regulatory landscape, embracing compliance automation is not just a trend but a strategic necessity. Organizations that adopt AI-powered compliance automation tools like BRYTER's PolicyAI platform can make compliance more accessible, efficient, and effective for all stakeholders. By harnessing the power of technology, organizations can stay ahead of regulatory changes and minimize risks in today's complex business environment.\n",
      "\n",
      "Call to Action:\n",
      "Delve into the world of compliance automation with BRYTER's PolicyAI platform and see how AI can revolutionize your compliance processes. Visit lawassistant.ai to learn more about how AI is reshaping the compliance industry.\n"
     ]
    }
   ],
   "source": [
    "# import txt file for context\n",
    "\n",
    "context = \"\" \n",
    "with open('/home/vince/projects/ai-workflows/context/blog_post_context.txt', 'r') as file:\n",
    "    context = file.read().replace('\\n', '')\n",
    "    \n",
    "\n",
    "\n",
    "def main():\n",
    "    topic = \"Compliance automation using AI\"\n",
    "    context\n",
    "    style = \"informative\"  # Options: \"persuasive\", \"narrative\", \"descriptive\", \"informative\"\n",
    "    word_count = 750\n",
    "    audience = \"general public\"  # Options might include \"general public\", \"professionals\", \"students\", etc.\n",
    "    tone = \"neutral\"  # Options could be \"formal\", \"casual\", \"optimistic\", \"serious\", etc.\n",
    "\n",
    "    # Generate the blog post as json\n",
    "    \n",
    "    # blog_post = generate_blog_post(topic, context, style, word_count, audience, tone)\n",
    "    # print(json.dumps(blog_post, indent=4))\n",
    "    \n",
    "    # Generate the blog post as regular text\n",
    "    blog_post = generate_blog_as_text(topic, context, style, word_count, audience, tone)\n",
    "    print(blog_post)\n",
    "    return blog_post\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
